# Practical GAM

One of the more powerful modeling packages in R comes with its installation[^gampack].  The mixed gam computational vehical, or <span class="pack">mgcv</span> pacakage, is an extremely flexible modeling tool, and one we'll use for our foray into generalized additive models.  If you're familiar with standard regression models, the syntax is little different, but adds a great many possibilities to your efforts.


## Getting started


So GAMs can be seen as a special type of GLM, that extends the model to incorporate nonlinear and other relationships.  Behind the scenes, extra columns are added to our model matrix to do this, but their associated coefficients are penalized to help avoid overfitting.

As we will see, the main syntactical difference between using <span class="func">gam</span> and using <span class="func">glm</span> is that you'll use the <span class="func">s</span> function to incorporate <span class="emph">smooth terms</span>, or classes that include basis functions as we saw before, along with a penalty.  Beyond what we did previously, mgcv also incorporates a penalized regression approach.  For those familiar with lasso, ridge or other penalized approaches you'll find the same idea here[^penalty].  For those new to this, it's important to add the concept and technique to your statistcal modeling toolbox.

Let's look at some more interesting data. For the following example we'll use the iris data set.  Just kidding! We'll look at some data regarding the Internet Movie Database (IMDB) from the <span class="pack">ggplot2movies</span> package. If you want to you'll need to install it, the data object is called 'movies'.  For information, type `r ?movies` after loading the package.  However, our example will concern yearly averages based on that data set `movies_yearly`, with a film budget variable that has been adjusted to 2016 dollars. In addition, I've grouped them by whether they are an action movie or not in a separate data set `movies_yearly_action`.


```{r movies_data_setup, eval=FALSE, echo=FALSE, cache=TRUE}
library(ggplot2movies)
library(lubridate)
monthly_cpi = read_csv('data/CPIAUCSL.csv') # from https://fred.stlouisfed.org/
monthly_cpi$year = year(monthly_cpi$DATE)

yearly_cpi = monthly_cpi %>%
  mutate(year = year(DATE)) %>% 
  group_by(year) %>%
  summarize(cpi = mean(CPIAUCSL)) %>% 
  mutate(adj_factor = cpi/cpi[year == 2016])

movies = left_join(movies, yearly_cpi) %>% 
  filter(!is.na(budget)) %>% 
  mutate(budget_2016 = budget/adj_factor)



movies_yearly_action = movies %>% 
  filter(!is.na(budget_2016)) %>% #length>60, 
  mutate(Action=factor(Action, labels=c('Other', 'Action'))) %>% 
  group_by(year, Action) %>%
  mutate(N=n()) %>% 
  summarise_at(.cols = vars(budget_2016, rating, votes, length, N), 
               .funs = funs('_'= round(mean(.), digits=1))) %>% # unclear why renaming variables based on function is REQUIRED
  rename(budget_2016=budget_2016__,
         rating=rating__,
         votes=votes__,
         length=length__,
         N=N__) %>% 
  mutate(budget_2016 = budget_2016/1e6,
         votes = votes/1000,
         length = length/60) %>% 
  ungroup()


movies_yearly = movies %>% 
  filter(!is.na(budget_2016)) %>% #length>60, 
  group_by(year) %>% 
  mutate(N=n()) %>% 
  summarise_at(.cols = vars(budget_2016, rating, votes, length,N), 
               .funs = funs('_'= round(mean(.), digits=1))) %>% 
  rename(budget_2016=budget_2016__,
         rating=rating__,
         votes=votes__,
         length=length__,
         N=N__) %>% 
  mutate(budget_2016 = budget_2016/1e6,
         votes = votes/1000,
         length = length/60) %>% 
  ungroup()

save(movies_yearly, movies_yearly_action, file='data/movies_yearly.RData')

# movies_yearly %>% 
#   plot_ly() %>% 
#   add_markers(~Budget, ~Rating, size=~Votes)
# movies_yearly %>% 
#   add_predictions(model=gam(Rating ~ s(year), data=.)) %>% 
#   plot_ly() %>% 
#   add_markers(~year, ~Rating, size=~Votes) %>% 
#   add_lines(~year, ~pred)
# movies_yearly %>% 
#   add_predictions(model=gam(Rating ~ s(year, by=Action, bs='fs'), data=.)) %>% 
#   plot_ly() %>% 
#   add_markers(~year, ~Rating, size=~Votes) %>% 
#   add_lines(~year, ~pred, color=~Action)
# movies_yearly %>% 
#   add_predictions(model=gam(Rating ~ s(year, by=Action, bs='fs'), data=.)) %>% 
#   ggplot(aes(year, Rating)) +
#   geom_point() +
#   geom_line(aes(y=pred, color=Action)) +
#   theme_ipsum_rc() +
#   lazerhawk::theme_trueMinimal() 
# ggplotly()

```


```{r readimdb, echo=1:2}
library(ggplot2movies)
load(file='data/movies_yearly.RData')
DT::datatable(movies_yearly, options=list(dom='pt', scrollX=T, scrollY=T), width='100%')
```

<br>
Let's examine the the time trend for ratings and budget. Size of the points represents the number of movies that year.
<br>

```{r rating_trend, echo=F}
movies_yearly %>% 
  plot_ly() %>% 
  add_markers(~year, ~rating, color=I('#ff5503'), size=~N, showlegend=F) %>% 
  theme_plotly()
```

For ratings there seems to be a definite curvilinear trend, where initially ratings for movies started high and decreased, but were on the upswing at later years.

Adjusted for inflation, movie budgets don't increase linearly over time as one might expect, and in fact were decreasing towards the end.


```{r budget_trend, echo=F}
movies_yearly %>% 
  plot_ly() %>% 
  add_markers(~year, ~budget_2016, color=I('#ff5503'), size=~N, showlegend=F) %>% 
  theme_plotly()
```

## Fitting the model

Let's fit a gam to the yearly trend for ratings.  I will also put in budget (in millions), movie length (in hours), and number of votes (in thousands) as standard effects.  We'll use a cubic regression spline for our basis, `bs='cr'`, but aside from specifying the smooth term, the syntax is the same as one would use for the <span class="func">glm</span> function.
<br>

```{r gam_rating}
library(mgcv)
gam_model = gam(rating ~ s(year, bs='cr') + budget_2016 + votes + length, 
                data=movies_yearly)
summary(gam_model)
```

The first part of our output contains standard linear regression results. It is important to note that there is nothing going on here that you haven't seen in any other GLM. For example, in this case there is no relationship between budget and rating, whereas adding an hour to the film might bump the rating around half a point.

```{r parametric, echo=FALSE}
cat("Parametric coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) 4.8976286  0.5393570   9.080 6.96e-12 ***
budget_2016 0.0008481  0.0076005   0.112    0.912    
votes       0.0247742  0.0243371   1.018    0.314    
length      0.5706696  0.3687635   1.548    0.128     ")
```


The next part contains our information regarding the smooth terms, of which there is only one.


```{r nonparametric, echo=FALSE}
cat("Approximate significance of smooth terms:
          edf Ref.df    F p-value    
s(year) 7.309  8.283 8.07 1.6e-07 ***")
```

While this suggests a statistically significant effect, it's important to note there is not a precisely defined p-value in this setting- it clearly states 'approximate significance'.  For some more details see the [technical section][Technical details] or [my document](https://m-clark.github.io/docs/GAM.html), but for now, we'll  start with the <span class="emph">effective degrees of freedom</span>, or edf. In typical OLS regression the model degrees of freedom is equivalent to the number of predictors/terms in the model. This is not so straightforward with a GAM due to the smoothing process and the penalized regression estimation procedure. In this example there are actually 9 terms associated with this smooth, but they are each penalized to some extent and thus the *effective* degrees of freedom does not equal 9. For hypothesis testing an alternate edf is actually used, which is the other one provided there in the summary result (Ref.df). 

The edf would equal 1 if the model penalized the smooth term to a simple linear relationship[^allthewaytozero], and so the effective degrees of freedom falls somewhere betweeen 1 and k-1, where k is chosen based on the basis. You can think of it as akin to the number of knots.  The default here was 10. Basically if it's 1, just leave it as a linear component, or if it's close to k, maybe bump up the default to allow for more wiggliness.


### Visualizing the effects

While helpful to some extent, the best way to interpret smooth terms is visually.  The ability to do so is easy, you can just use the <span class="func">plot</span> method on the model object. However, the default plot may be difficult to grasp at first.  It is a [component plot](https://en.wikipedia.org/wiki/Partial_residual_plot#CCPR_plot), which plots the original variable against the linear combination of its basis functions, i.e. the sum of each basis function multiplied by its respective coefficient. For example, if we were using a quadratic polynomial, it would be the plot of $x$ against $b_1\cdot x + b_2\cdot x^2$. For GAMs, $y$ is also centered, and what you end up with is something like the following.

```{r gamplot, dev='svglite'}
plot(gam_model)
```

So this tells us the contribution of the year to the model fit. For an alternative, consider the <span class="pack">visreg</span> package, which will put it back on the original scale and just look slightly nicer while allowing for more control.

```{r visreg, dev='svglite'}
library(visreg)
visreg(gam_model, xvar='year', partial=F)
```

Again, we're see the fit after partialling out the effects of budget, number of votes, and length.

You of course can look at predictions at any relevant values for the covariates, as you can with any other model. Consider the following effect of time while keeping budget and length constant at their means, and votes at 1000[^atmeans].

```{r gam_predict}
movies_yearly %>% 
  transmute(budget_2016 = mean(budget_2016),
            length = mean(length),
            votes = 1,
            year=1948:2005) %>% 
  add_predictions(gam_model) %>% 
  plot_ly() %>% 
  add_lines(~year, ~pred)
```

In the end, controlling for budget, length, and popularity, movie quality decreased notably until 1960, and remained at that level until the late 90s, when quality increased almost as dramatically.








[^gampack]: For reasons I've not understood, other packages still depend on or extend the <span class="pack">gam</span> package, which doesn't possess anywhere near the functionality (though the authors literally wrote the book on GAM).

[^penalty]: a quadratic penalty specifically

[^imdb]: One might think this would be more interesting data, but there is actually not much variability in scores.  They have a mean of `r round(mean(movies$rating), 1)` and standard deviation, of `r round(sd(movies$rating), 1)`, with some skew (notable duds).  Other variables are notable rounded.

[^atmeans]: If we had put votes at its mean, you would basically duplicate the original plot.

[^allthewaytozero]: You can actually penalize the covariate right out of the model if desired, i.e. edf=0.