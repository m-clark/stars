# Issues

There are some complexities associated with GAMs that will take some getting used to.

- **Choice of distribution**: With <span class="pack">mgcv</span> you have more options than the standard GLM, i.e. it generalizes beyond the exponential family of distributions, so put some thought into what you think might best represent the data generating process.

- **Choice of smooth**: Some might be particularly appropriate to a given situation (e.g. spatial). In many situations you'll have a choice. They should not lead to fundamentally different conclusions though. As an example, here's the result of the same model with several different smooths with the default `k`. See `?smooth.terms` for the choices available.

```{r vispline, dev='svglite', echo=FALSE}
gam_model2 = gam(rating ~ s(year) + budget_2016 + votes + length, data=movies_yearly)
gam_model3 = gam(rating ~ s(year, bs='ps') + budget_2016 + votes + length, data=movies_yearly)
gam_model4 = gam(rating ~ s(year, bs='gp') + budget_2016 + votes + length, data=movies_yearly)
movies_yearly %>% 
  na.omit() %>%
  transmute(budget_2016 = mean(budget_2016),
            length = mean(length),
            votes = 1,
            year=year) %>% 
  add_predictions(gam_model,  var='Prediction') %>% 
  add_predictions(gam_model2, var='Predicted_tp') %>% 
  add_predictions(gam_model3, var='Predicted_ps') %>% 
  add_predictions(gam_model3, var='Predicted_gp') %>% 
  plot_ly() %>% 
  add_lines(~year, ~Prediction, name='Cubic Spline') %>% 
  add_lines(~year, ~Predicted_tp, name='Thin Plate') %>% 
  add_lines(~year, ~Predicted_ps, name='P-Spline') %>% 
  add_lines(~year, ~Predicted_gp, name='Gaussian Process')
```


- **Choosing whether to keep an effect linear**: Sometimes it may look like the effect isn't nonlinear or much more more than linear, and a choice will have to be made whether to go the simpler route.  If `k=1`, this is straightforward. If not exactly, you might have to make a choice.

- **Diagnostics**: There are some additional diagnostics to consider, such as the `k` parameter.  <span class="emph">Concurvity</span>, which is collinearity for the GAM setting, also comes into play.

- **Model comparison**: In general one can use AIC as with standard GLMs, and in addition one has the GCV statistic. However, there are special considerations for an ANOVA style approach, so see `?anova.gam` for details.

- **Fuzzy p-values**: For folks that are used to complex models, e.g. penalized regression, mixed models, machine learning techniques, this is not new.  For those new to such models, you must unlearn what you have learned.

- **Areas of little data**: The fit can become highly variable when data is sparse. The standard errors of the plots will be very wide in those areas, and you should avoid going too far with any conclusions drawn for those data points.


Just like with any new statistical modeling technique, diving in with something you're already familiar with is a good way to start getting comfortable.  One way to do so would be to revisit an analysis you've done in the past and re-analyze it with a GAM.  And don't forget, you also have an [entire text](https://www.crcpress.com/Generalized-Additive-Models-An-Introduction-with-R/Wood/p/book/9781584884743) devoted to the package for as much detail as you want, and the help files are quite detailed as well.